x-hadoop-common: &hadoop-common
  image: apache/hadoop:3.3.5
  user: root
  environment: &hadoop-common-env
    HADOOP_HOME: /opt/hadoop


services:
  namenode:
    <<: *hadoop-common
    container_name: namenode
    environment: 
      <<: *hadoop-common-env
      JMX_PORT: 8001
      JMX_FILE_NAME: namenode
    volumes: 
      - hadoop-namenode-volume:/opt/hadoop/data/nameNode
      - ../hadoop/hadoop-config:/opt/hadoop/etc/hadoop
      - ../hadoop/other:/hadoop-conf
    ports:
      - "13870:9870" # WEB UI
      - "13001:8001" # JMX
    command: [ "/bin/bash", "/hadoop-conf/init-scripts/start-hdfs.sh" ]

  datanode1:
    <<: *hadoop-common
    container_name: datanode1
    hostname: datanode1
    environment:
      <<: *hadoop-common-env
      JMX_PORT: 8002
      JMX_FILE_NAME: datanode
    volumes: 
      - hadoop-datanode1-volume:/opt/hadoop/data/dataNode
      - ../hadoop/hadoop-config:/opt/hadoop/etc/hadoop
      - ../hadoop/other:/hadoop-conf
    ports:
      - "13002:8002" # JMX
      - "12040:8081" # Spark-worker-1
    command: [ "/bin/bash", "/hadoop-conf/init-scripts/init-datanode.sh" ]
    depends_on:
      - namenode

volumes:
  hadoop-namenode-volume:
  hadoop-datanode1-volume: