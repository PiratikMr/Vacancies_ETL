DB {
    host = "app-postgres"
    port = "5432"
    baseName = "vacstorage"
    userName = "postgres"
    userPassword = "1234"
}

FS {
    url = "hdfs://namenode:9000"
    path = "VacStorage/"
}

Spark {
    name = "SparkApp"
    master = "spark://spark-master:7077" # spark://spark-master:7077
    driverMemory = "1g"
    driverCores = "1"
    executorMemory = "6g"
    executorCores = "7"
}

URL {
    headers {
        User-agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
    }

    requestsPerSecond = 30
    maxConcurrentStreams = 8 # not used
    timeout = 30000 # milliseconds
}

# common arguments
Arguments {
    
    # transform part

    transformPartitions = 1

    # update part

    updateLimit = 5000
}

Dags {
    ScalaVersion = "2.12"
    SparkConnId = "SPARK_CONN"
    PostgresConnId = "POSTGRES_CONN"
    TimeZone = "Asia/Krasnoyarsk"

    ETL {
        fileName = "{{ data_interval_end.strftime('%Y-%m-%d') }}"
    }

    RefreshMatViews {
        schedule = ""
        concurrency = 5
    }

    DeleteData {
        schedule = ""
        hdfsPrefix = "docker exec namenode"
        concurrency = 5

        rawData = 60
        transformedData = 120
    }
}